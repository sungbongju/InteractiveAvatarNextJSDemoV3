/**
 * ================================================
 * InteractiveAvatar.tsx - V3 ì‡¼í•‘ëª° AI ìƒë‹´ ì•„ë°”íƒ€
 * ================================================
 *
 * DB ì—°ë™ ë²„ì „ (Knowledge Base ì‚¬ìš© ì•ˆ í•¨)
 * - ë¡œê·¸ì¸ ì‹œ ê³ ê° ì •ë³´ ë°›ì•„ì„œ ì¸ì‚¬
 * - route.ts í†µí•´ OpenAI + ê³ ê°ì •ë³´ ê¸°ë°˜ ì‘ë‹µ
 * - Web Speech APIë¡œ ìŒì„± ì¸ì‹
 *
 * ================================================
 */

import {
  AvatarQuality,
  StreamingEvents,
  VoiceEmotion,
  StartAvatarRequest,
  ElevenLabsModel,
  TaskType,
} from "@heygen/streaming-avatar";
import { useEffect, useRef, useState, useCallback } from "react";
import { useMemoizedFn, useUnmount } from "ahooks";

import { useStreamingAvatarSession } from "./logic/useStreamingAvatarSession";
import { StreamingAvatarProvider, StreamingAvatarSessionState } from "./logic";
import { WebSpeechRecognizer } from "@/app/lib/webSpeechAPI";

// ============================================
// ğŸ”§ ì„¤ì •
// ============================================

// ì•„ë°”íƒ€ ID (Wayne ê³ ì •)
const AVATAR_ID = "Wayne_20240711";

// âŒ Knowledge Base ì‚¬ìš© ì•ˆ í•¨ (DB ì—°ë™ ìœ„í•´)
const KNOWLEDGE_ID = "";

// ì•„ë°”íƒ€ ì„¤ì •
const AVATAR_CONFIG: StartAvatarRequest = {
  quality: AvatarQuality.Low,
  avatarName: AVATAR_ID,
  // knowledgeId ì œê±°!
  voice: {
    rate: 1.2,
    emotion: VoiceEmotion.FRIENDLY,
    model: ElevenLabsModel.eleven_flash_v2_5,
  },
  language: "ko",
};

// ============================================
// ë©”ì¸ ì»´í¬ë„ŒíŠ¸
// ============================================
function InteractiveAvatar() {
  const {
    initAvatar,
    startAvatar,
    stopAvatar,
    sessionState,
    stream,
    avatarRef,
  } = useStreamingAvatarSession();

  // UI ìƒíƒœ
  const [isLoading, setIsLoading] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [isAvatarSpeaking, setIsAvatarSpeaking] = useState(false);
  const [interimTranscript, setInterimTranscript] = useState("");
  const mediaStream = useRef<HTMLVideoElement>(null);

  // ë‚´ë¶€ ìƒíƒœ refs
  const isProcessingRef = useRef(false);
  const hasGreetedRef = useRef(false);
  const hasStartedRef = useRef(false);
  const webSpeechRef = useRef<WebSpeechRecognizer | null>(null);
  const isAvatarSpeakingRef = useRef(false);

  // ğŸ†• ê³ ê° ì •ë³´ ref
  const customerRef = useRef<any>(null);
  // ëŒ€í™” íˆìŠ¤í† ë¦¬
  const chatHistoryRef = useRef<{ role: string; content: string }[]>([]);

  // ============================================
  // API í˜¸ì¶œ
  // ============================================
  const fetchAccessToken = async () => {
    const response = await fetch("/api/get-access-token", { method: "POST" });
    const token = await response.text();
    return token;
  };

  // ğŸ†• Chat API í˜¸ì¶œ (route.ts)
  const callChatAPI = async (
    type: string,
    params: Record<string, any> = {}
  ): Promise<string> => {
    try {
      const response = await fetch("/api/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          type,
          customer: customerRef.current,
          history: chatHistoryRef.current,
          ...params,
        }),
      });
      const data = await response.json();
      return data.reply || "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.";
    } catch (error) {
      console.error("Chat API error:", error);
      return "ì„œë²„ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.";
    }
  };

  // ============================================
  // ì•„ë°”íƒ€ ìŒì„± ì¶œë ¥
  // ============================================
  const speakWithAvatar = useCallback(
    async (text: string) => {
      if (!avatarRef.current || !text) return;

      try {
        console.log("ğŸ”‡ Web Speech ì¼ì‹œì •ì§€");
        isAvatarSpeakingRef.current = true;
        setIsAvatarSpeaking(true);
        webSpeechRef.current?.pause();

        console.log("ğŸ—£ï¸ Avatar speak:", text);
        await avatarRef.current.speak({
          text,
          taskType: TaskType.REPEAT,
        });
      } catch (error: any) {
        console.error("Avatar speak error:", error);
        
        // 401 ì—ëŸ¬ë©´ ì„¸ì…˜ ì¬ì‹œì‘ í•„ìš”
        if (error?.message?.includes("401") || error?.status === 401) {
          console.log("ğŸ”„ í† í° ë§Œë£Œ - ì„¸ì…˜ ì¬ì‹œì‘ í•„ìš”");
          hasStartedRef.current = false;
          hasGreetedRef.current = false;
        }
        
        isAvatarSpeakingRef.current = false;
        setIsAvatarSpeaking(false);
        webSpeechRef.current?.resume();
      }
    },
    [avatarRef],
  );

  // ============================================
  // ğŸ†• ì¸ì‚¬ë§ ìƒì„± (ê³ ê° ì •ë³´ ê¸°ë°˜)
  // ============================================
  const generateGreeting = useCallback(async () => {
    const customer = customerRef.current;

    if (customer) {
      // DBì—ì„œ ë°›ì€ ê³ ê° ì •ë³´ë¡œ ì¸ì‚¬
      const reply = await callChatAPI("greeting");
      return reply;
    } else {
      return "ì•ˆë…•í•˜ì„¸ìš”! AI ìƒë‹´ì› ë°ëª¨ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!";
    }
  }, []);

  // ============================================
  // ì‚¬ìš©ì ìŒì„± ì²˜ë¦¬ (route.ts í˜¸ì¶œ)
  // ============================================
  const handleUserSpeech = useCallback(
    async (transcript: string) => {
      if (isAvatarSpeakingRef.current) {
        console.log("â¸ï¸ ì•„ë°”íƒ€ê°€ ë§í•˜ëŠ” ì¤‘ - ë¬´ì‹œ:", transcript);
        return;
      }

      if (!transcript.trim() || isProcessingRef.current) return;

      isProcessingRef.current = true;
      setIsLoading(true);
      setInterimTranscript("");
      console.log("ğŸ¯ User said:", transcript);

      try {
        await avatarRef.current?.interrupt();
      } catch {
        // ignore
      }

      // ğŸ†• route.ts í˜¸ì¶œí•´ì„œ ì‘ë‹µ ë°›ê¸°
      const reply = await callChatAPI("chat", { message: transcript });

      // ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
      chatHistoryRef.current.push({ role: "user", content: transcript });
      chatHistoryRef.current.push({ role: "assistant", content: reply });

      // ì•„ë°”íƒ€ê°€ ë§í•˜ê¸°
      await speakWithAvatar(reply);

      setIsLoading(false);
      isProcessingRef.current = false;
    },
    [avatarRef, speakWithAvatar],
  );

  // ============================================
  // Web Speech API ì´ˆê¸°í™”
  // ============================================
  const initWebSpeech = useCallback(() => {
    if (webSpeechRef.current) {
      console.log("ğŸ¤ Web Speech ì´ë¯¸ ì´ˆê¸°í™”ë¨");
      return;
    }

    if (!WebSpeechRecognizer.isSupported()) {
      console.error("ğŸ¤ Web Speech API ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €");
      alert(
        "ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome ë˜ëŠ” Edgeë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.",
      );
      return;
    }

    console.log("ğŸ¤ Web Speech API ì´ˆê¸°í™” ì¤‘...");

    webSpeechRef.current = new WebSpeechRecognizer(
      {
        onResult: (transcript: string, isFinal: boolean) => {
          if (isAvatarSpeakingRef.current) {
            return;
          }

          if (isFinal) {
            console.log("ğŸ¤ ìµœì¢… ì¸ì‹:", transcript);
            setInterimTranscript("");
            handleUserSpeech(transcript);
          } else {
            setInterimTranscript(transcript);
          }
        },

        onStart: () => {
          if (!isAvatarSpeakingRef.current) {
            setIsListening(true);
          }
        },

        onEnd: () => {
          setIsListening(false);
        },

        onSpeechStart: () => {
          if (!isAvatarSpeakingRef.current) {
            setIsListening(true);
          }
        },

        onSpeechEnd: () => {
          setTimeout(() => {
            if (!isAvatarSpeakingRef.current) {
              setIsListening(false);
            }
          }, 500);
        },

        onError: (error: string) => {
          console.error("ğŸ¤ Web Speech ì—ëŸ¬:", error);
          if (error === "not-allowed") {
            alert(
              "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.",
            );
          }
        },
      },
      {
        lang: "ko-KR",
        continuous: true,
        interimResults: true,
        autoRestart: true,
      },
    );

    console.log("ğŸ¤ Web Speech API ì´ˆê¸°í™” ì™„ë£Œ");
  }, [handleUserSpeech]);

  // ============================================
  // ì„¸ì…˜ ì´ˆê¸°í™”
  // ============================================
  const resetSession = useMemoizedFn(async () => {
    console.log("ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™” ì¤‘...");

    if (webSpeechRef.current) {
      webSpeechRef.current.destroy();
      webSpeechRef.current = null;
    }

    try {
      await stopAvatar();
    } catch (e) {
      console.log("stopAvatar ì—ëŸ¬ (ë¬´ì‹œ):", e);
    }

    hasStartedRef.current = false;
    hasGreetedRef.current = false;
    isProcessingRef.current = false;
    isAvatarSpeakingRef.current = false;
    chatHistoryRef.current = [];
    setIsLoading(false);
    setIsListening(false);
    setIsAvatarSpeaking(false);
    setInterimTranscript("");

    await new Promise((r) => setTimeout(r, 500));
    console.log("ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ");
  });

  // ============================================
  // ì„¸ì…˜ ì‹œì‘
  // ============================================
  const startSession = useMemoizedFn(async () => {
    if (hasStartedRef.current) {
      console.log("âš ï¸ ì´ë¯¸ ì„¸ì…˜ ì‹œì‘ë¨, ë¬´ì‹œ");
      return;
    }
    hasStartedRef.current = true;

    try {
      // ê¸°ì¡´ ì•„ë°”íƒ€ ì •ë¦¬
      if (avatarRef.current) {
        try {
          await avatarRef.current.stopAvatar();
        } catch (e) {
          // ë¬´ì‹œ
        }
      }

      const token = await fetchAccessToken();
      console.log("ğŸ”‘ ìƒˆ í† í° ë°œê¸‰ ì™„ë£Œ");
      const avatar = initAvatar(token);

      avatar.on(StreamingEvents.STREAM_READY, async () => {
        console.log("âœ… Stream ready");

        if (!hasGreetedRef.current) {
          await new Promise((r) => setTimeout(r, 1500));

          // ğŸ†• ê³ ê° ì •ë³´ ê¸°ë°˜ ì¸ì‚¬ë§ ìƒì„±
          const greeting = await generateGreeting();
          await speakWithAvatar(greeting);

          hasGreetedRef.current = true;
        }
      });

      avatar.on(StreamingEvents.STREAM_DISCONNECTED, () => {
        console.log("âŒ Stream disconnected");
        hasGreetedRef.current = false;
        hasStartedRef.current = false;
        webSpeechRef.current?.destroy();
        webSpeechRef.current = null;
      });

      avatar.on(StreamingEvents.AVATAR_START_TALKING, () => {
        console.log("ğŸ—£ï¸ Avatar started talking - Web Speech ì¼ì‹œì •ì§€");
        isAvatarSpeakingRef.current = true;
        setIsAvatarSpeaking(true);
        webSpeechRef.current?.pause();
      });

      avatar.on(StreamingEvents.AVATAR_STOP_TALKING, async () => {
        console.log("ğŸ”ˆ Avatar stopped talking - Web Speech ì¬ê°œ");
        isAvatarSpeakingRef.current = false;
        setIsAvatarSpeaking(false);
        await new Promise((r) => setTimeout(r, 500));
        webSpeechRef.current?.resume();
        console.log("ğŸ¤ Web Speech ì¬ê°œ ì™„ë£Œ");
      });

      await startAvatar(AVATAR_CONFIG);

      console.log("ğŸ¤ Web Speech API ì‹œì‘...");
      initWebSpeech();

      setTimeout(() => {
        webSpeechRef.current?.start();
        console.log("ğŸ¤ Web Speech ì¸ì‹ ì‹œì‘");
      }, 2000);
    } catch (error) {
      console.error("Session error:", error);
      hasStartedRef.current = false;
    }
  });

  // ============================================
  // ë§ˆì´í¬ í† ê¸€
  // ============================================
  const toggleMicrophone = useCallback(() => {
    if (!webSpeechRef.current) {
      initWebSpeech();
      setTimeout(() => {
        webSpeechRef.current?.start();
      }, 100);
      return;
    }

    if (webSpeechRef.current.getIsPaused()) {
      webSpeechRef.current.resume();
    } else {
      webSpeechRef.current.pause();
    }
  }, [initWebSpeech]);

  // ============================================
  // postMessage í†µì‹  (ì™¸ë¶€ í˜ì´ì§€ ì—°ë™ìš©)
  // ============================================
  useEffect(() => {
    const handleMessage = async (event: MessageEvent) => {
      const { type, customer } = event.data || {};

      switch (type) {
        case "RESET_AVATAR":
        case "STOP_AVATAR":
          console.log(`ğŸ“¥ ${type}`);
          await resetSession();
          break;

        case "START_AVATAR":
          console.log("ğŸ“¥ START_AVATAR");
          await resetSession();
          startSession();
          break;

        case "CUSTOMER_LOGIN":
          console.log("ğŸ“¥ CUSTOMER_LOGIN:", customer);
          // ì´ë¯¸ ì‹œì‘ ì¤‘ì´ë©´ ë¬´ì‹œ
          if (hasStartedRef.current) {
            console.log("âš ï¸ ì´ë¯¸ ì„¸ì…˜ ì§„í–‰ ì¤‘ - ê³ ê° ì •ë³´ë§Œ ì—…ë°ì´íŠ¸");
            customerRef.current = customer;
            return;
          }
          customerRef.current = customer;
          chatHistoryRef.current = [];
          // ë¡œê·¸ì¸í•˜ë©´ ë°”ë¡œ ì•„ë°”íƒ€ ì‹œì‘!
          await resetSession();
          await new Promise((r) => setTimeout(r, 300));
          startSession();
          break;

        case "CUSTOMER_LOGOUT":
          console.log("ğŸ“¥ CUSTOMER_LOGOUT");
          customerRef.current = null;
          chatHistoryRef.current = [];
          await resetSession();
          break;

        case "USER_MESSAGE":
          // ì™¸ë¶€ì—ì„œ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
          const { message } = event.data || {};
          if (message && !isProcessingRef.current) {
            console.log("ğŸ“¥ USER_MESSAGE:", message);
            isProcessingRef.current = true;
            setIsListening(false);
            webSpeechRef.current?.pause();

            try {
              const response = await callChatAPI("chat", { message });
              await speakWithAvatar(response);
            } catch (error) {
              console.error("USER_MESSAGE ì²˜ë¦¬ ì—ëŸ¬:", error);
            } finally {
              isProcessingRef.current = false;
            }
          }
          break;
      }
    };

    window.addEventListener("message", handleMessage);
    return () => window.removeEventListener("message", handleMessage);
  }, [resetSession, startSession]);

  // ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useUnmount(() => {
    webSpeechRef.current?.destroy();
    try {
      stopAvatar();
    } catch {
      // ignore
    }
  });

  // ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—°ê²°
  useEffect(() => {
    if (stream && mediaStream.current) {
      mediaStream.current.srcObject = stream;
      mediaStream.current.onloadedmetadata = () => mediaStream.current?.play();
    }
  }, [stream]);

  // ============================================
  // UI í—¬í¼
  // ============================================
  const getStatusText = () => {
    if (isAvatarSpeaking) return "ë§í•˜ëŠ” ì¤‘...";
    if (isListening) return "ë“£ëŠ” ì¤‘...";
    if (isLoading) return "ìƒê° ì¤‘...";
    return "ë§ì”€í•˜ì„¸ìš”";
  };

  const getStatusColor = () => {
    if (isAvatarSpeaking) return "bg-blue-500";
    if (isListening) return "bg-red-500 animate-pulse";
    if (isLoading) return "bg-yellow-500";
    return "bg-green-500";
  };

  // ============================================
  // ë Œë”ë§ - PIP ìµœì í™” UI
  // ============================================
  return (
    <div className="w-full h-full flex flex-col bg-black">
      {sessionState === StreamingAvatarSessionState.CONNECTED && stream ? (
        <div className="flex-1 relative">
          {/* ì•„ë°”íƒ€ ë¹„ë””ì˜¤ */}
          <video
            ref={mediaStream}
            autoPlay
            playsInline
            className="w-full h-full object-cover"
          />

          {/* ì¢…ë£Œ ë²„íŠ¼ */}
          <button
            className="absolute top-2 right-2 w-8 h-8 bg-black/50 hover:bg-red-600 text-white rounded-full flex items-center justify-center text-sm transition-colors"
            onClick={resetSession}
            title="ì¢…ë£Œ"
          >
            âœ•
          </button>

          {/* ë§ˆì´í¬ í† ê¸€ ë²„íŠ¼ */}
          <button
            className={`absolute top-2 left-2 w-8 h-8 ${
              isListening
                ? "bg-red-500 animate-pulse"
                : "bg-black/50 hover:bg-green-600"
            } text-white rounded-full flex items-center justify-center text-sm transition-colors`}
            disabled={isAvatarSpeaking}
            onClick={toggleMicrophone}
            title={isListening ? "ë§ˆì´í¬ ë„ê¸°" : "ë§ˆì´í¬ ì¼œê¸°"}
          >
            {isListening ? "ğŸ¤" : "ğŸ™ï¸"}
          </button>

          {/* ìƒíƒœ í‘œì‹œ */}
          <div className="absolute bottom-2 left-2 flex items-center gap-2">
            <div className={`w-3 h-3 rounded-full ${getStatusColor()}`} />
            <span className="text-white text-xs bg-black/60 px-2 py-1 rounded">
              {getStatusText()}
            </span>
          </div>

          {/* ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ í‘œì‹œ */}
          {interimTranscript && (
            <div className="absolute bottom-12 left-2 right-2">
              <div className="bg-black/70 text-white text-xs px-3 py-2 rounded-lg">
                ğŸ¤ &quot;{interimTranscript}&quot;
              </div>
            </div>
          )}
        </div>
      ) : (
        /* ì‹œì‘ í™”ë©´ */
        <div className="w-full h-full flex items-center justify-center bg-gradient-to-br from-zinc-900 to-black">
          {sessionState === StreamingAvatarSessionState.CONNECTING ? (
            <div className="flex flex-col items-center gap-3 text-white">
              <div className="w-10 h-10 border-3 border-purple-500 border-t-transparent rounded-full animate-spin" />
              <span className="text-sm">ì—°ê²° ì¤‘...</span>
            </div>
          ) : (
            <button
              className="px-6 py-3 bg-purple-600 hover:bg-purple-700 text-white rounded-full text-base font-medium shadow-lg transition-colors flex items-center gap-2"
              onClick={startSession}
            >
              <span>ğŸ’¬</span>
              <span>ìƒë‹´ ì‹œì‘</span>
            </button>
          )}
        </div>
      )}
    </div>
  );
}

// ============================================
// Provider Wrapper
// ============================================
export default function InteractiveAvatarWrapper() {
  return (
    <StreamingAvatarProvider basePath={process.env.NEXT_PUBLIC_BASE_API_URL}>
      <InteractiveAvatar />
    </StreamingAvatarProvider>
  );
}
